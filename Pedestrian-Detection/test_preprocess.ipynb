{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml_for_person(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    images = []\n",
    "    annotations = []\n",
    "    category_id = [0, 1]  # We only have one category \"person\"\n",
    "    annotation_id = 0\n",
    "\n",
    "    # Iterate over all images\n",
    "    for image in root.findall('image'):\n",
    "        image_id = int(image.get('id'))\n",
    "        file_name = image.get('name')\n",
    "        width = int(image.get('width'))\n",
    "        height = int(image.get('height'))\n",
    "\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        # Iterate over all boxes in the image\n",
    "        for box in image.findall('box'):\n",
    "            label = box.get('label')\n",
    "\n",
    "            # We only process \"person\" labels\n",
    "            if label == \"person\" or label == \"dog\" or label == \"cat\":\n",
    "                if label == \"person\":\n",
    "                    category_id = 0\n",
    "                else:\n",
    "                    category_id = 1\n",
    "\n",
    "                occluded = int(box.get('occluded')) if box.get('occluded') is not None else 0\n",
    "                xtl = float(box.get('xtl'))\n",
    "                ytl = float(box.get('ytl'))\n",
    "                xbr = float(box.get('xbr'))\n",
    "                ybr = float(box.get('ybr'))\n",
    "\n",
    "                # Calculate width and height of the bounding box\n",
    "                bbox_width = xbr - xtl\n",
    "                bbox_height = ybr - ytl\n",
    "\n",
    "                z_order = int(box.get('z_order')) if box.get('z_order') is not None else 0\n",
    "\n",
    "                annotations.append({\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_id,  # 0 for person, 1 for objects\n",
    "                    \"bbox\": [xtl, ytl, bbox_width, bbox_height],\n",
    "                    \"area\": bbox_width * bbox_height,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"occluded\": occluded,\n",
    "                    \"z_order\": z_order\n",
    "                })\n",
    "                annotation_id += 1\n",
    "\n",
    "    return images, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save(xml_files, output_file_path):\n",
    "    cumulative_images = []\n",
    "    cumulative_annotations = []\n",
    "    cumulative_categories = [{\"id\": 0, \"name\": \"person\"}, {\"id\": 1, \"name\": \"objects\"}]  # Static category\n",
    "\n",
    "    image_id_counter = 0\n",
    "    annotation_id_counter = 0\n",
    "\n",
    "    for xml_file_path in xml_files:\n",
    "        images, annotations = parse_xml_for_person(xml_file_path)\n",
    "\n",
    "        # Adjust image and annotation IDs to be cumulative and unique\n",
    "        for img in images:\n",
    "            img['id'] = image_id_counter\n",
    "            cumulative_images.append(img)\n",
    "            image_id_counter += 1\n",
    "\n",
    "        for ann in annotations:\n",
    "            ann['id'] = annotation_id_counter\n",
    "            ann['image_id'] = ann['image_id'] + image_id_counter - len(images) - 1  # Adjusting image_id\n",
    "            cumulative_annotations.append(ann)\n",
    "            annotation_id_counter += 1\n",
    "\n",
    "        print(f'Processed {xml_file_path}')\n",
    "\n",
    "    # Combine everything into the COCO format\n",
    "    coco_format_data = {\n",
    "        \"images\": cumulative_images,\n",
    "        \"annotations\": cumulative_annotations,\n",
    "        \"categories\": cumulative_categories\n",
    "    }\n",
    "\n",
    "    # Save the combined data to a single JSON file\n",
    "    with open(output_file_path, 'w') as json_file:\n",
    "        json.dump(coco_format_data, json_file, indent=4)\n",
    "\n",
    "    print(f'Combined annotations saved to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import progressbar\n",
    "\n",
    "# Set the dataset path\n",
    "dataset_base_folder = '/content/drive/MyDrive/pedestrian/dataset/Bbox_13_new'  # Path to the base folder containing subfolders with XML files\n",
    "\n",
    "# Initialize the progress bar\n",
    "widgets = ['Scanning: ', progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]\n",
    "progress = progressbar.ProgressBar(widgets=widgets)\n",
    "\n",
    "# Get list of all XML files\n",
    "xml_files = []\n",
    "for subdir, _, files in progress(os.walk(dataset_base_folder)):\n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "            xml_file_path = os.path.join(subdir, file)\n",
    "            xml_files.append(xml_file_path)\n",
    "\n",
    "print(xml_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and val with 80:20 ratio\n",
    "train_files, val_files = train_test_split(xml_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Process and save train dataset\n",
    "train_output_path = '/content/drive/MyDrive/pedestrian/dataset/train_annotations_toy.json'\n",
    "process_and_save(train_files, train_output_path)\n",
    "\n",
    "# Process and save val dataset\n",
    "val_output_path = '/content/drive/MyDrive/pedestrian/dataset/val_annotations_toy.json'\n",
    "process_and_save(val_files, val_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import defaultdict\n",
    "import progressbar\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def parse_xml_for_person(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    images = []\n",
    "    annotations = []\n",
    "    annotation_id = 0\n",
    "\n",
    "    # Iterate over all images\n",
    "    for image in root.findall('image'):\n",
    "        image_id = int(image.get('id'))\n",
    "        file_name = image.get('name')\n",
    "        width = int(image.get('width'))\n",
    "        height = int(image.get('height'))\n",
    "\n",
    "        images.append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": file_name,\n",
    "            \"width\": width,\n",
    "            \"height\": height\n",
    "        })\n",
    "\n",
    "        # Iterate over all boxes in the image\n",
    "        for box in image.findall('box'):\n",
    "            label = box.get('label')\n",
    "\n",
    "            if label in [\"person\", \"dog\", \"cat\"]:\n",
    "                category_id = 0 if label == \"person\" else 1\n",
    "\n",
    "                occluded = int(box.get('occluded')) if box.get('occluded') is not None else 0\n",
    "                xtl = float(box.get('xtl'))\n",
    "                ytl = float(box.get('ytl'))\n",
    "                xbr = float(box.get('xbr'))\n",
    "                ybr = float(box.get('ybr'))\n",
    "\n",
    "                bbox_width = xbr - xtl\n",
    "                bbox_height = ybr - ytl\n",
    "\n",
    "                z_order = int(box.get('z_order')) if box.get('z_order') is not None else 0\n",
    "\n",
    "                annotations.append({\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": category_id,\n",
    "                    \"bbox\": [xtl, ytl, bbox_width, bbox_height],\n",
    "                    \"area\": bbox_width * bbox_height,\n",
    "                    \"iscrowd\": 0,\n",
    "                    \"occluded\": occluded,\n",
    "                    \"z_order\": z_order\n",
    "                })\n",
    "                annotation_id += 1\n",
    "\n",
    "    return images, annotations\n",
    "\n",
    "def process_and_save(xml_files, output_file_path):\n",
    "    cumulative_images = []\n",
    "    cumulative_annotations = []\n",
    "    cumulative_categories = [{\"id\": 0, \"name\": \"person\"}, {\"id\": 1, \"name\": \"objects\"}]\n",
    "\n",
    "    image_id_counter = 0\n",
    "    annotation_id_counter = 0\n",
    "\n",
    "    for xml_file_path in xml_files:\n",
    "        images, annotations = parse_xml_for_person(xml_file_path)\n",
    "\n",
    "        for img in images:\n",
    "            img['id'] = image_id_counter\n",
    "            cumulative_images.append(img)\n",
    "            image_id_counter += 1\n",
    "\n",
    "        for ann in annotations:\n",
    "            ann['id'] = annotation_id_counter\n",
    "            ann['image_id'] = ann['image_id'] + image_id_counter - len(images)  # Adjusting image_id\n",
    "            cumulative_annotations.append(ann)\n",
    "            annotation_id_counter += 1\n",
    "\n",
    "        print(f'Processed {xml_file_path}')\n",
    "\n",
    "    coco_format_data = {\n",
    "        \"images\": cumulative_images,\n",
    "        \"annotations\": cumulative_annotations,\n",
    "        \"categories\": cumulative_categories\n",
    "    }\n",
    "\n",
    "    with open(output_file_path, 'w') as json_file:\n",
    "        json.dump(coco_format_data, json_file, indent=4)\n",
    "\n",
    "    print(f'Combined annotations saved to {output_file_path}')\n",
    "\n",
    "dataset_base_folder = '/content/drive/MyDrive/pedestrian/dataset/'\n",
    "\n",
    "widgets = ['Scanning: ', progressbar.Percentage(), ' ', progressbar.Bar(), ' ', progressbar.ETA()]\n",
    "progress = progressbar.ProgressBar(widgets=widgets)\n",
    "\n",
    "xml_files = []\n",
    "for subdir, _, files in progress(os.walk(dataset_base_folder)):\n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "            xml_file_path = os.path.join(subdir, file)\n",
    "            xml_files.append(xml_file_path)\n",
    "\n",
    "train_files, val_files = train_test_split(xml_files, test_size=0.2, random_state=42)\n",
    "\n",
    "train_output_path = '/content/drive/MyDrive/pedestrian/dataset/train_annotations_1.json' #train_annotations_1=유진 only 데이터셋\n",
    "process_and_save(train_files, train_output_path)\n",
    "\n",
    "val_output_path = '/content/drive/MyDrive/pedestrian/dataset/val_annotations_1.json'\n",
    "process_and_save(val_files, val_output_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
