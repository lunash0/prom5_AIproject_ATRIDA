# -*- coding: utf-8 -*-
"""aihub_preprocess.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HmeUsF2Hwg_OWhV7nke28D5FQoX6PDKd
"""

import os
from zipfile import ZipFile
from xml.etree import ElementTree
import json
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')

zip_file = ZipFile('/content/drive/My Drive/dataset/Bbox_4_new.zip') # (압축이 해제되지 않은) 학습할 데이터셋 zip file 위치경로
zip_file.extractall('/content/drive/My Drive/dataset/') # 압축을 해제할 '/위치경로/'

import xml.etree.ElementTree as ET
import json
import os

# Function to parse XML and filter for "person" labels
def parse_xml_for_person(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    images = []
    annotations = []
    category_id = 1  # We only have one category "person"
    annotation_id = 1

    # Iterate over all images
    for image in root.findall('image'):
        image_id = int(image.get('id'))
        file_name = image.get('name')
        width = int(image.get('width'))
        height = int(image.get('height'))

        images.append({
            "id": image_id,
            "file_name": file_name,
            "width": width,
            "height": height
        })

        # Iterate over all boxes in the image
        for box in image.findall('box'):
            label = box.get('label')

            # We only process "person" labels
            if label == "person":
                occluded = int(box.get('occluded'))
                xtl = float(box.get('xtl'))
                ytl = float(box.get('ytl'))
                xbr = float(box.get('xbr'))
                ybr = float(box.get('ybr'))

                # Calculate width and height of the bounding box
                bbox_width = xbr - xtl
                bbox_height = ybr - ytl

                annotations.append({
                    "id": annotation_id,
                    "image_id": image_id,
                    "category_id": category_id,  # "person" category
                    "bbox": [xtl, ytl, bbox_width, bbox_height],
                    "area": bbox_width * bbox_height,
                    "iscrowd": 0,
                    "occluded": occluded,
                    "z_order": int(box.get('z_order'))
                })

                annotation_id += 1

    return images, annotations

# Initialize cumulative lists to store all images and annotations
cumulative_images = []
cumulative_annotations = []
cumulative_categories = [{"id": 1, "name": "person"}]  # Static category

image_id_counter = 1
annotation_id_counter = 1

# Set the dataset path and output path here
dataset_base_folder = '/content/drive/My Drive/dataset'  # Path to the base folder containing subfolders with XML files
output_file_path = '/content/drive/My Drive/dataset/combined_person_annotations.json'  # Path to the final output JSON file

# Iterate through all subdirectories
for subdir, _, files in os.walk(dataset_base_folder):
    for file in files:
        if file.endswith('.xml'):
            xml_file_path = os.path.join(subdir, file)

            images, annotations = parse_xml_for_person(xml_file_path)

            # Adjust image and annotation IDs to be cumulative and unique
            for img in images:
                img['id'] = image_id_counter
                cumulative_images.append(img)
                image_id_counter += 1

            for ann in annotations:
                ann['id'] = annotation_id_counter
                ann['image_id'] = ann['image_id'] + image_id_counter - len(images) - 1  # Adjusting image_id
                cumulative_annotations.append(ann)
                annotation_id_counter += 1

            print(f'Processed {file} from {subdir}')

# Combine everything into the COCO format
coco_format_data = {
    "images": cumulative_images,
    "annotations": cumulative_annotations,
    "categories": cumulative_categories
}

# Save the combined data to a single JSON file
with open(output_file_path, 'w') as json_file:
    json.dump(coco_format_data, json_file, indent=4)

print(f'Combined annotations saved to {output_file_path}')
